---
title: "Getting Started: Generating Configs and Inputs"
owner: PCF Platform Automation
---

## <a id='requirements'></a> Requirements

* Deployed Concourse
* Persisted datastore that can be accessed by Concourse resource (e.g. s3, gcs, minio)
* Pivnet access to [Platform Automation](https://network.pivotal.io/products/platform-automation/)

<p class="note">
  <strong>Note</strong>: The Platform Automation for PCF is based on Concourse CI, it is recommended that you
  have some familiarity with Conocurse before getting started. If you are new to Concourse, 
  <a href="https://docs.pivotal.io/p-concourse/3-0/guides.html">Concourse CI Tutorials</a> would be a good place to start.
</p>

* a valid [env file]: this file will contain credentials necessary to login to Ops Manager using the `om` CLI. 
It is used by every task within Platform Automation for PCF
* a valid [auth file]: this file will contain the credentials necessary to create the Ops Manager login the first time
the VM is created. The choices for this file are simple or saml authentication.  

<p class="note">
  <strong>Note</strong>: There will be some crossover between the auth file and the env file due to how om is 
  setup and how the system works. It is highly recommended to parameterize these values, and let a credential
  management system (such as Credhub) fill in these values for you in order to maintain consistency across files.
</p>

* a [director configuration] file: Each Ops Manager needs its own configuration, but it is retrieved differently from
a product configuration. This config is used to deploy a new Ops Manager director, or update an existing one. 
* a set of valid [product configuration] files: Each product configuration is a yaml file that contains the properties
necessary to configure an Ops Manager product tile using the `om` tool. This can be used during install or update. 

## <a id='setup'></a> Setup

1. Download the latest version of [Platform Automation](https://network.pivotal.io/products/platform-automation/) from Pivnet.
   You will need:
   * `Concourse Tasks`
   * `Docker Image for Concourse Tasks`
   
   <p class="note">
     <strong>Note</strong>: If the pivnet link does not work for you, you might not have access to the product! Please
     communicate this in the #pcf-automation slack channel until the project is GA 
   </p>
   
   
1. Store the `platform-automation-image-*.tgz` in a blobsotre that can be accessed via a Concourse pipeline.

1. Store the `platform-automation-tasks-*.zip` in a blobstore that can be accessed via a Concourse pipeline.

1. Next we'll create a test pipeline to see if the assets can be accessed correctly.
   This pipeline runs a test task, which ensures that all the parts work correctly. 
   (the example pipeline assumes s3 as the blobstore)
   
    ```
    resources:
    - name: platform-automation-tasks-s3
      type: s3
      source:
        access_key_id: ((access_key_id))
        secret_access_key: ((secret_access_key))
        region_name: ((region))
        bucket: ((bucket))
        regexp: platform-automation-tasks-(.*).zip
    
    - name: platform-automation-image-s3
      type: s3
      source:
        access_key_id: ((access_key_id))
        secret_access_key: ((secret_access_key))
        region_name: ((region))
        bucket: ((bucket))
        regexp: platform-automation-image-(.*).tgz
    
    jobs:
    - name: test-resources
      plan:
      - aggregate:
        - get: platform-automation-tasks-s3
          params:
            unpack: true
        - get: platform-automation-image-s3
          params:
            unpack: true
      - task: test-resources
        image: platform-automation-image-s3
        file: platform-automation-tasks-s3/tasks/test.yml
    ```
    
    Fill in the S3 resource credentials and set the above pipeline on your Concourse instance.
<p class="note">
  <strong>Note</strong>: The pipeline can use any blobstore.
  We choose S3 because the resource natively supported by Concourse.
  S3 resource also supports S3-compatible blobstores (e.g. minio).
  See <a href="https://github.com/concourse/s3-resource#source-configuration">S3 Resource</a>
  for more information. If you want to use other blobstore, you need to provide a custom
   <a href="https://concourse-ci.org/resource-types.html">resource type</a> .
</p>

## <a id='generate-env-file'></a>Generating an Env File
Almost all [`om`][om] commands require an env file
to hit authenticated API endpoints.

The configuration for authentication has a dependency on either username/password

<%= yield_for_code_snippet from: 'pivotal-cf/platform-automation', at: 'env' %>

or client SAML setup.

<%= yield_for_code_snippet from: 'pivotal-cf/platform-automation', at: 'env-uaa' %>

## <a id='generate-auth-file'></a>Generating an Auth File
These configuration formats match the configuration for setting up authentication.
See the documentation for the [`configure-authentication`][configure-authentication]
or [`configure-saml-authentication`][configure-saml-authentication] task for details.

The configuration for authentication has a dependency on either username/password

<%= yield_for_code_snippet from: 'pivotal-cf/platform-automation', at: 'auth-configuration' %>

or client SAML setup.

<%= yield_for_code_snippet from: 'pivotal-cf/platform-automation', at: 'saml-auth-configuration' %>

## <a id='generate-director-configuration'></a>Generating Director Configuration
To generate the configuration for an Ops Manager, you will need the following (Just like a tile):

1. a running Ops Manager
  - this is accomplished by running the following tasks:
      - [create-vm]
      - [configure-authentication] or [configure-saml-authentication]
      - [configure-director]
      - [apply-director-changes]

1. Configure Ops Manager _manually_ within the Ops Manager UI (Instructions for doing so can be found
using the [Official PCF Documentation])

1. Run the following command to get the staged config:

```bash
docker import ${PLATFORM_AUTOMATION_IMAGE_TGZ} pcf-automation-image
docker run -it --rm -v $PWD:/workspace -w /workspace pcf-automation-image \
om --env ${ENV_FILE} staged-director-config --include-placeholders
```

Where `${PLATFORM_AUTOMATION_IMAGE_TGZ}` is the image file downloaded from Pivnet, and `${ENV_FILE}` is the [env file] 
required for all tasks. The resulting file can then be parameterized, saved, and uploaded to a persistent 
blobstore(i.e. s3, gcs, azure blobstore, etc).

Alternatively, you can add the following task to your pipeline to generate and persist this for you:

<%= yield_for_code_snippet from: 'pivotal-cf/platform-automation', at: 'staged-director-config' %>

<p class="note">
  <strong>Note</strong>: staged-director-config will not be able to grab all sensitive fields in your Ops Manager 
  installation (for example: vcenter_username and vcenter_password if using vsphere). To find these missing fields,
  please refer to the <a href="https://docs.pivotal.io/pivotalcf/opsman-api/">Ops Manager API Documentation</a>
</p>

## <a id='generate-product-configuration'></a>Generating Product Configuration
To generate the configuration for a tile, you will need the following:

1. a running Ops Manager
  - this is accomplished by running the following tasks:
      - [create-vm]
      - [configure-authentication] or [configure-saml-authentication]
      - [configure-director]
      - [apply-director-changes]
  
1. The tile you wish to have a config file for needs to be [uploaded and staged] in the Ops Manager
environment

1. Configure the tile _manually_ within the Ops Manager UI (Instructions for PAS can be found
using the [Official PCF Documentation])

1. Run the following command to get the staged config:

```bash
docker import ${PLATFORM_AUTOMATION_IMAGE_TGZ} pcf-automation-image
docker run -it --rm -v $PWD:/workspace -w /workspace pcf-automation-image \
om --env ${ENV_FILE} staged-config --product-name ${PRODUCT_SLUG} --include-credentials
```

Where `${PLATFORM_AUTOMATION_IMAGE_TGZ}` is the image file downloaded from Pivnet,and `${ENV_FILE}` is the [env file] required for all tasks, and `${PRODUCT_SLUG}` is the name of the product
downloaded from [pivnet]. The resulting file can then be parameterized, saved, and uploaded to a 
persistent blobstore(i.e. s3, gcs, azure blobstore, etc).

Alternatively, you can add the following task to your pipeline to generate and persist this for you:

<%= yield_for_code_snippet from: 'pivotal-cf/platform-automation', at: 'staged-config' %>


## <a id='manage-configration'></a>Managing Configuration, Auth, and State Files
To use all these files with the Concourse tasks that require them,
you need to make them available as Concourse Resources.
They’re all text files, and there are many resource types that can work for this - in our examples,
we use s3 compatible blobstores. As with the tasks and image,
you’ll need to upload them to a bucket and declare a resource in your pipeline for each file you need.

## <a id='your-own-pipeline'></a>Making Your Own Pipeline
If the example pipeline doesn’t work for you, that’s okay! It probably shouldn’t.
You know your environment and constraints, and we don’t.
We recommend you look at the tasks that make up the pipeline,
and see if they can be arranged such that they do what you need. 
If you have Platform Architects available, they can help you look at this problem.

Our example just illustrates the tasks and provides one possible starting place
- the suggested starting projects provide other starting places that make different choices.
Your pipeline is yours, not a fork of something we wrote.

If the tasks themselves don’t work for you, we’d like to hear from you.
We might be able to help you figure out how to make it work,
or we can use the feedback to improve the tasks so they’re a better fit for what you need.
If you need to write your own tasks in the meantime, our tasks are designed with clear interfaces,
and should be able to coexist in a pipeline with tasks from other sources, or custom tasks you develop yourself.

[apply-director-changes]: ./task-reference.html#apply-director-changes
[auth file]: ./getting-started.html#generate-auth-file
[configure-authentication]: ./task-reference.html#configure-authentication
[configure-director]: ./task-reference.html#configure-director
[concourse-documentation]: https://github.com/concourse/s3-resource
[configure-saml-authentication]: ./task-reference.html#configure-saml-authentication
[create-vm]: ./task-reference.html#create-vm
[director configuration]: ./getting-started.html#generate-director-configuration
[env file]: ./getting-started.html#generate-env-file
[Official PCF Documentation]: https://docs.pivotal.io/pivotalcf/installing/index.html
[om]: https://github.com/pivotal-cf/om
[pivnet]: https://network.pivotal.io
[product configuration]: ./getting-started.html#generate-product-configuration
[staged-config]: ./task-reference.html#staged-config
[staged-director-config]: ./task-reference.html#staged-director-config
[uploaded-and-staged]: ./task-reference.html#upload-and-stage-product
